{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32 , kernel_size=3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "\n",
    "        self.module_fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.module_conv(x)\n",
    "        x = x.view(-1, )\n",
    "        x = self.module_fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (module_conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (module_fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================Model의 output===========================\n",
      "tensor([ 0.0706, -0.0357, -0.0233, -0.0446,  0.0563,  0.0246,  0.0906,  0.1282,\n",
      "         0.0206,  0.0325], grad_fn=<ViewBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==========================SoftMax의 결과==============================\n",
      "tensor([0.1038, 0.0933, 0.0945, 0.0925, 0.1023, 0.0991, 0.1059, 0.1099, 0.0987,\n",
      "        0.0999], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==========================예측한 결과==============================\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongseungmin/anaconda3/envs/fastapi/lib/python3.12/site-packages/torch/nn/modules/module.py:1553: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_data_smape = torch.rand(3, 28, 28)\n",
    "model_output = model(train_data_smape)\n",
    "\n",
    "print('==========================Model의 output===========================',)\n",
    "print(model_output, end = '\\n\\n\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('==========================SoftMax의 결과==============================')\n",
    "pred = nn.Softmax()(model_output)\n",
    "print(pred, end = '\\n\\n\\n\\n\\n')\n",
    "\n",
    "\n",
    "print('==========================예측한 결과==============================')\n",
    "result = pred.argmax().item()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: CNN(\n",
      "  (module_conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (module_fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: module_conv.0.weight | Size: torch.Size([32, 3, 3, 3]) | Values : tensor([[[[ 0.0503, -0.0914, -0.0202],\n",
      "          [ 0.1800,  0.0438, -0.0012],\n",
      "          [ 0.0986,  0.0895,  0.1064]],\n",
      "\n",
      "         [[ 0.1354,  0.1740,  0.1860],\n",
      "          [ 0.0768,  0.0968, -0.0209],\n",
      "          [-0.0491,  0.0533,  0.0307]],\n",
      "\n",
      "         [[ 0.0515,  0.1117,  0.0832],\n",
      "          [-0.1264, -0.0308,  0.0987],\n",
      "          [ 0.0279, -0.0770,  0.1743]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1225, -0.1230,  0.0150],\n",
      "          [-0.1546,  0.1080, -0.1811],\n",
      "          [ 0.1414, -0.1761, -0.1070]],\n",
      "\n",
      "         [[ 0.0126,  0.1881, -0.1454],\n",
      "          [ 0.0530,  0.1653, -0.1599],\n",
      "          [-0.1770,  0.0540,  0.0527]],\n",
      "\n",
      "         [[-0.0638,  0.1908, -0.1214],\n",
      "          [ 0.0092, -0.0723, -0.1338],\n",
      "          [-0.1376, -0.0339,  0.1026]]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: module_conv.0.bias | Size: torch.Size([32]) | Values : tensor([-0.0787,  0.0012], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: module_conv.3.weight | Size: torch.Size([64, 32, 3, 3]) | Values : tensor([[[[ 3.8320e-02, -4.5826e-02, -2.9717e-02],\n",
      "          [-3.5687e-02,  3.0378e-03, -5.7326e-03],\n",
      "          [-3.7877e-02,  4.9445e-03, -2.8725e-02]],\n",
      "\n",
      "         [[-1.7261e-02,  2.9240e-02,  5.5402e-02],\n",
      "          [ 5.6866e-02,  2.6400e-02, -3.1572e-02],\n",
      "          [-1.9777e-02,  5.2105e-02, -1.4065e-02]],\n",
      "\n",
      "         [[ 5.7737e-02,  2.5121e-02, -5.3803e-02],\n",
      "          [-2.9364e-02,  4.3646e-02, -5.2874e-02],\n",
      "          [ 2.8576e-02, -3.8537e-02,  5.7210e-02]],\n",
      "\n",
      "         [[-4.0669e-02,  4.7174e-02, -4.2269e-03],\n",
      "          [-2.3006e-02, -4.2884e-03,  6.9294e-03],\n",
      "          [-2.8875e-03, -1.4676e-02,  2.7838e-03]],\n",
      "\n",
      "         [[-5.3773e-02,  1.1919e-02, -4.1783e-02],\n",
      "          [ 3.8083e-02,  2.3344e-02, -3.4051e-02],\n",
      "          [-3.7445e-02,  3.3951e-02, -3.8756e-02]],\n",
      "\n",
      "         [[ 4.1860e-02,  8.8415e-03, -4.4373e-02],\n",
      "          [ 2.3619e-02, -3.6269e-02,  2.0540e-02],\n",
      "          [ 1.1100e-02, -1.9414e-02,  3.7558e-02]],\n",
      "\n",
      "         [[-2.3157e-02, -2.2197e-02, -1.2917e-02],\n",
      "          [-5.1342e-02, -8.7976e-03,  5.6734e-02],\n",
      "          [ 2.4928e-03,  3.5707e-02,  5.4446e-02]],\n",
      "\n",
      "         [[ 1.5324e-02,  3.2352e-02,  5.1572e-02],\n",
      "          [-3.0299e-02, -5.2570e-02,  2.1162e-02],\n",
      "          [ 4.0059e-02, -1.0361e-02, -5.7158e-02]],\n",
      "\n",
      "         [[-6.1787e-03,  2.9089e-02, -5.3477e-02],\n",
      "          [-7.5310e-03,  4.5813e-02, -3.6213e-02],\n",
      "          [-4.0906e-02, -2.4024e-02, -2.6258e-02]],\n",
      "\n",
      "         [[ 1.5432e-02, -1.4994e-02, -1.2242e-02],\n",
      "          [-3.6134e-02,  5.5822e-02, -2.8172e-03],\n",
      "          [-2.7887e-02,  1.0376e-02, -9.0517e-03]],\n",
      "\n",
      "         [[-3.3692e-02, -2.4391e-02,  1.5419e-02],\n",
      "          [-4.4824e-02, -9.5807e-03, -5.1406e-02],\n",
      "          [-3.2039e-02, -3.3073e-02, -3.4744e-02]],\n",
      "\n",
      "         [[-1.4609e-02, -4.0797e-02,  2.2522e-02],\n",
      "          [-8.7643e-03,  5.5057e-02, -2.0913e-02],\n",
      "          [ 2.5045e-02, -5.0858e-02,  8.6000e-03]],\n",
      "\n",
      "         [[ 1.1688e-02, -4.3874e-02,  7.2552e-04],\n",
      "          [ 5.7630e-02,  1.8111e-02, -4.8302e-02],\n",
      "          [ 5.3504e-02, -5.1309e-02,  5.8746e-02]],\n",
      "\n",
      "         [[-2.6519e-02, -4.3751e-02, -3.0492e-02],\n",
      "          [ 1.6038e-02,  5.4946e-02,  4.2124e-03],\n",
      "          [ 1.5193e-02, -3.3786e-02,  1.5688e-02]],\n",
      "\n",
      "         [[ 6.7379e-03,  2.3897e-02, -2.9315e-02],\n",
      "          [-3.7138e-02, -4.5028e-02,  2.6972e-02],\n",
      "          [-4.1935e-02,  3.1342e-02,  3.2059e-02]],\n",
      "\n",
      "         [[-1.2036e-02, -2.9540e-02,  4.0507e-02],\n",
      "          [ 2.4553e-02, -3.9603e-02, -4.6332e-02],\n",
      "          [-3.1120e-02, -4.5002e-02,  2.9651e-02]],\n",
      "\n",
      "         [[ 2.7453e-02, -2.1281e-02,  6.1044e-03],\n",
      "          [-5.5369e-02,  8.8778e-03, -5.0246e-02],\n",
      "          [-2.7091e-02,  3.9481e-02, -4.1760e-02]],\n",
      "\n",
      "         [[-1.3376e-02, -2.6509e-02, -2.3143e-03],\n",
      "          [ 5.4084e-02, -3.5290e-02,  3.1078e-02],\n",
      "          [ 4.4578e-02, -5.2795e-02,  5.8241e-02]],\n",
      "\n",
      "         [[-2.6033e-03,  4.1089e-02, -5.7057e-03],\n",
      "          [ 5.7970e-02, -8.0123e-03, -1.0397e-02],\n",
      "          [-4.3995e-02,  3.5450e-02, -1.4035e-02]],\n",
      "\n",
      "         [[ 4.5798e-02,  1.5130e-02, -2.9398e-02],\n",
      "          [ 2.4710e-03,  3.6378e-02, -4.0218e-03],\n",
      "          [ 9.3520e-03, -5.4422e-02,  5.7147e-02]],\n",
      "\n",
      "         [[ 3.8080e-02,  5.9225e-04, -4.5674e-02],\n",
      "          [ 1.1363e-02,  5.5846e-02,  5.5634e-06],\n",
      "          [-2.1003e-02, -2.6593e-02,  5.8494e-02]],\n",
      "\n",
      "         [[ 5.4908e-02,  4.5297e-03, -1.6466e-02],\n",
      "          [ 4.8024e-02,  1.0523e-02,  3.3710e-02],\n",
      "          [ 2.7920e-02, -1.8503e-02, -1.2442e-02]],\n",
      "\n",
      "         [[-1.7196e-02,  5.8772e-03, -4.5510e-02],\n",
      "          [ 4.2728e-02, -6.5928e-03, -2.6992e-02],\n",
      "          [ 3.3364e-02,  4.2359e-02, -2.4090e-02]],\n",
      "\n",
      "         [[-4.0088e-02,  2.0130e-02, -2.3858e-02],\n",
      "          [-5.1371e-03,  2.4752e-02, -3.1597e-02],\n",
      "          [ 4.5378e-02,  1.1842e-02,  5.8742e-02]],\n",
      "\n",
      "         [[-4.0080e-02, -4.7000e-02,  3.0845e-02],\n",
      "          [-1.1722e-03,  2.9669e-02, -5.4420e-02],\n",
      "          [ 3.4286e-02, -3.7378e-02,  4.3706e-02]],\n",
      "\n",
      "         [[ 2.3920e-02, -4.2419e-02,  5.7165e-02],\n",
      "          [-1.0364e-02,  2.7988e-02,  3.0402e-02],\n",
      "          [ 2.1501e-02, -2.3710e-02, -5.5187e-02]],\n",
      "\n",
      "         [[ 4.9278e-02,  1.9511e-02, -3.8932e-02],\n",
      "          [ 1.0283e-02, -1.8590e-02,  5.0860e-02],\n",
      "          [-3.4118e-02, -4.2790e-02,  1.9467e-02]],\n",
      "\n",
      "         [[ 5.8709e-03,  2.2087e-03,  5.2638e-02],\n",
      "          [ 4.9698e-02, -4.4509e-02, -3.7013e-02],\n",
      "          [-5.3735e-02,  5.0797e-03, -5.4274e-02]],\n",
      "\n",
      "         [[-3.2776e-02,  4.7683e-02,  3.9347e-02],\n",
      "          [-4.0024e-02, -2.7699e-02,  4.8704e-02],\n",
      "          [ 3.9024e-02, -4.0820e-02, -6.7478e-03]],\n",
      "\n",
      "         [[ 5.6590e-02, -5.4908e-02, -2.2128e-02],\n",
      "          [ 5.8741e-02, -1.6172e-02,  2.0112e-02],\n",
      "          [ 4.6166e-02,  4.1803e-02, -1.3387e-02]],\n",
      "\n",
      "         [[-5.3482e-03, -3.8254e-02, -4.9015e-02],\n",
      "          [ 2.9725e-02,  5.4104e-02, -3.6061e-02],\n",
      "          [ 9.3058e-03,  1.5670e-02,  3.0818e-02]],\n",
      "\n",
      "         [[ 4.5885e-02, -4.5699e-02,  1.8258e-03],\n",
      "          [ 1.0950e-02,  5.8409e-02, -4.3850e-02],\n",
      "          [ 3.4156e-02, -4.6634e-02, -4.3176e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2129e-02,  4.1660e-02,  3.7918e-02],\n",
      "          [ 3.5543e-02,  1.1134e-03,  5.2074e-02],\n",
      "          [-5.6818e-02,  2.0164e-02,  4.1311e-02]],\n",
      "\n",
      "         [[ 5.6804e-02,  5.4773e-03, -5.3660e-02],\n",
      "          [ 5.4528e-02, -4.6410e-03,  5.1201e-02],\n",
      "          [ 5.6440e-02,  5.3902e-02,  1.0108e-02]],\n",
      "\n",
      "         [[ 2.6080e-02, -2.5034e-02, -3.2381e-02],\n",
      "          [-2.2818e-02,  4.4485e-02, -2.7062e-02],\n",
      "          [ 2.2921e-02,  4.9670e-03, -2.4275e-02]],\n",
      "\n",
      "         [[-5.4496e-02, -5.1135e-02, -6.9886e-03],\n",
      "          [ 2.4767e-03, -3.1807e-03, -2.6829e-02],\n",
      "          [ 2.9992e-02,  1.8741e-02, -4.7369e-02]],\n",
      "\n",
      "         [[-4.8521e-02,  2.0503e-02, -5.3923e-03],\n",
      "          [-9.0202e-04,  7.2001e-03, -1.4158e-02],\n",
      "          [-5.0172e-02, -3.8311e-02, -2.7434e-02]],\n",
      "\n",
      "         [[-4.2201e-02, -1.8734e-02,  1.2981e-02],\n",
      "          [ 5.1740e-02, -1.0678e-02,  2.2354e-02],\n",
      "          [-3.2133e-02,  2.5126e-02,  4.5824e-03]],\n",
      "\n",
      "         [[ 2.6580e-02,  2.6154e-02,  3.9911e-02],\n",
      "          [-1.7031e-02, -2.6253e-02,  1.7560e-02],\n",
      "          [-7.3698e-03,  4.9433e-02, -7.0249e-04]],\n",
      "\n",
      "         [[ 4.3534e-02,  5.5895e-02, -3.6952e-03],\n",
      "          [ 2.7156e-02,  3.2452e-02, -5.5472e-02],\n",
      "          [ 1.1878e-02,  6.6595e-03, -3.5007e-02]],\n",
      "\n",
      "         [[-2.7025e-02, -2.4991e-02,  1.4447e-02],\n",
      "          [ 1.6568e-02,  5.7299e-02, -7.2702e-03],\n",
      "          [ 2.8754e-03,  4.7195e-02,  4.6468e-03]],\n",
      "\n",
      "         [[-3.5840e-02, -2.0322e-02,  9.4956e-03],\n",
      "          [ 3.0181e-02,  3.3942e-03,  1.5378e-02],\n",
      "          [ 3.7246e-02, -1.3007e-02, -5.6939e-02]],\n",
      "\n",
      "         [[-7.2640e-05, -3.1588e-02, -2.4382e-02],\n",
      "          [ 1.7032e-02,  5.2372e-02, -3.4017e-02],\n",
      "          [-4.7288e-02,  3.0618e-02, -4.0709e-02]],\n",
      "\n",
      "         [[ 4.3842e-02,  2.4136e-02,  5.4099e-02],\n",
      "          [-3.0898e-02,  2.3473e-03,  1.0806e-02],\n",
      "          [ 3.2386e-02,  5.3754e-02, -5.7698e-02]],\n",
      "\n",
      "         [[ 8.6854e-03,  1.8944e-02,  4.7490e-02],\n",
      "          [ 5.2451e-02,  4.0996e-02,  5.6347e-02],\n",
      "          [ 3.7379e-02,  3.4922e-02, -3.2174e-02]],\n",
      "\n",
      "         [[-5.0607e-02, -5.6587e-02,  1.1377e-02],\n",
      "          [ 4.0919e-02,  5.5738e-02, -2.8864e-02],\n",
      "          [ 3.7485e-03, -8.2693e-03, -5.0308e-03]],\n",
      "\n",
      "         [[ 2.3624e-02,  5.2043e-02,  3.9340e-02],\n",
      "          [ 4.0410e-02, -5.8315e-02,  2.8888e-02],\n",
      "          [ 9.5436e-03,  1.6084e-02,  1.4881e-02]],\n",
      "\n",
      "         [[-1.3509e-02, -3.0407e-02,  5.7063e-02],\n",
      "          [ 4.0695e-02,  2.8158e-02, -2.1392e-02],\n",
      "          [-5.5075e-02, -2.0863e-02,  2.9981e-02]],\n",
      "\n",
      "         [[ 3.9023e-03, -2.6507e-03,  9.0046e-03],\n",
      "          [ 9.7175e-03, -5.1615e-02, -5.1352e-02],\n",
      "          [ 1.6064e-03,  6.5025e-03,  5.5890e-03]],\n",
      "\n",
      "         [[-3.5299e-02, -1.3895e-02, -1.4792e-02],\n",
      "          [-3.2919e-02,  3.0725e-02, -4.1825e-02],\n",
      "          [-2.7136e-03, -5.0056e-02, -3.3785e-02]],\n",
      "\n",
      "         [[-5.5678e-03, -2.4881e-03,  2.0048e-02],\n",
      "          [-1.1112e-02,  5.0422e-02, -4.9035e-02],\n",
      "          [-9.8958e-03,  1.7905e-02,  3.6785e-02]],\n",
      "\n",
      "         [[-4.5638e-03,  7.5661e-03,  1.3024e-02],\n",
      "          [ 2.3673e-02, -1.4423e-03,  5.5187e-02],\n",
      "          [-2.3506e-02, -7.3511e-05, -5.2417e-02]],\n",
      "\n",
      "         [[-4.7233e-02,  3.9388e-02,  2.6222e-02],\n",
      "          [ 1.0714e-02,  3.8907e-02,  3.3183e-02],\n",
      "          [ 3.9178e-02, -5.5212e-02, -5.0618e-02]],\n",
      "\n",
      "         [[-4.7440e-02,  5.3043e-02, -1.7798e-02],\n",
      "          [ 3.2569e-02,  4.8488e-02, -5.7222e-02],\n",
      "          [ 5.7312e-03,  5.1809e-02, -4.1711e-02]],\n",
      "\n",
      "         [[-5.5998e-02,  2.5071e-02,  4.7140e-02],\n",
      "          [ 2.4888e-02, -4.2808e-02,  1.1272e-02],\n",
      "          [-3.8323e-02,  5.3960e-02,  1.1747e-02]],\n",
      "\n",
      "         [[ 4.8638e-02,  5.1555e-02, -4.9729e-02],\n",
      "          [-1.1737e-02, -1.6629e-02, -3.8567e-02],\n",
      "          [ 1.8901e-02, -2.7689e-02, -3.2738e-02]],\n",
      "\n",
      "         [[-4.6674e-02,  5.0471e-03,  3.3927e-02],\n",
      "          [ 9.9992e-03,  2.0449e-02, -5.2081e-02],\n",
      "          [ 1.0658e-02,  4.9063e-03, -1.2417e-03]],\n",
      "\n",
      "         [[ 3.0557e-02,  1.7465e-02,  1.6457e-02],\n",
      "          [-3.8113e-02,  2.8831e-02, -3.1580e-02],\n",
      "          [-5.4422e-02,  3.5125e-02, -4.0657e-02]],\n",
      "\n",
      "         [[ 2.9978e-02, -2.5286e-02,  3.8517e-02],\n",
      "          [ 1.7914e-02,  3.9426e-02, -6.1738e-03],\n",
      "          [-1.0041e-02,  5.4482e-02, -8.2069e-03]],\n",
      "\n",
      "         [[ 4.4316e-02, -3.6173e-02, -5.0313e-02],\n",
      "          [ 3.5935e-02, -5.4175e-02, -1.1661e-02],\n",
      "          [-3.4138e-02, -2.5474e-02, -1.9131e-02]],\n",
      "\n",
      "         [[-3.9090e-02,  1.9204e-02, -3.2432e-02],\n",
      "          [-5.8111e-02,  4.1495e-02, -5.3517e-02],\n",
      "          [-4.2434e-02,  2.5758e-02, -7.7458e-03]],\n",
      "\n",
      "         [[-3.5981e-02, -4.8255e-02, -1.5727e-02],\n",
      "          [ 2.3617e-02, -3.5398e-02,  4.5787e-02],\n",
      "          [-4.5342e-02, -3.0958e-02,  2.0852e-02]],\n",
      "\n",
      "         [[ 1.6194e-02,  2.8580e-02,  3.3758e-03],\n",
      "          [ 3.4165e-02,  2.7481e-02, -3.7397e-02],\n",
      "          [-3.7400e-02,  1.9921e-02,  3.0322e-02]],\n",
      "\n",
      "         [[ 5.6737e-02, -2.9015e-03,  1.3967e-02],\n",
      "          [-3.4416e-03, -4.7105e-02, -3.7195e-02],\n",
      "          [ 3.6193e-02,  4.7616e-02, -3.6040e-03]]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: module_conv.3.bias | Size: torch.Size([64]) | Values : tensor([ 0.0395, -0.0368], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: module_fc.0.weight | Size: torch.Size([256, 3136]) | Values : tensor([[ 0.0157, -0.0045, -0.0175,  ..., -0.0114,  0.0036, -0.0108],\n",
      "        [ 0.0115,  0.0077, -0.0085,  ..., -0.0103, -0.0025,  0.0048]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: module_fc.0.bias | Size: torch.Size([256]) | Values : tensor([ 0.0051, -0.0135], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: module_fc.2.weight | Size: torch.Size([10, 256]) | Values : tensor([[-1.2417e-02,  4.2300e-02,  4.7622e-02,  5.9200e-02,  3.1071e-02,\n",
      "         -4.0700e-02,  2.9049e-02, -1.3742e-03, -5.3592e-02, -3.0651e-02,\n",
      "          1.6069e-02,  2.8146e-02, -5.2599e-02,  5.5838e-02,  1.8164e-02,\n",
      "         -2.9397e-02,  3.0415e-02,  4.5806e-02, -2.6451e-02,  5.2294e-02,\n",
      "          3.6458e-02,  5.7036e-02,  3.8277e-02,  4.8956e-02,  2.3463e-02,\n",
      "          1.3864e-02,  3.6907e-02, -2.8096e-02,  3.6575e-02,  1.6172e-02,\n",
      "          4.6399e-02, -2.5041e-02, -1.0395e-02,  8.9083e-03,  6.1297e-02,\n",
      "         -6.1452e-02, -5.2404e-03,  1.6241e-02, -1.0094e-02, -2.3307e-02,\n",
      "          4.5899e-02,  2.6301e-02, -5.0870e-02,  4.3749e-02, -4.9086e-02,\n",
      "          2.6609e-02,  4.2584e-02,  3.5107e-02,  3.6065e-02, -5.8514e-02,\n",
      "          5.2907e-02,  2.6675e-02,  5.7713e-02,  3.4201e-02, -2.0300e-02,\n",
      "          2.7919e-02,  4.0316e-02,  4.8304e-02,  5.2918e-02, -8.5194e-03,\n",
      "         -1.0284e-02,  2.7818e-02, -4.1642e-02,  1.1629e-02,  2.9005e-02,\n",
      "          3.9138e-02,  2.1299e-02, -4.9911e-02, -3.5964e-02,  4.0619e-02,\n",
      "          3.8355e-02, -3.1593e-02,  5.5647e-02, -1.0146e-02,  6.0695e-02,\n",
      "         -7.3948e-03,  3.6677e-02, -6.1550e-02,  1.7805e-02, -4.2367e-02,\n",
      "         -3.9137e-02, -3.1873e-02, -2.5086e-02,  1.5367e-02, -4.9420e-02,\n",
      "          4.8201e-02,  3.4854e-02, -1.9167e-03,  5.5437e-02,  5.8379e-02,\n",
      "          1.7816e-02,  1.1315e-02,  6.2152e-02,  5.1871e-02, -1.1925e-02,\n",
      "         -5.0629e-02,  1.2654e-02, -3.2693e-02, -1.4320e-02,  4.0490e-02,\n",
      "         -2.4052e-03,  3.4391e-02,  4.0954e-03,  4.9240e-02, -6.1440e-02,\n",
      "          1.0994e-02,  3.9716e-02, -6.2125e-02,  1.9032e-02, -5.3713e-02,\n",
      "          7.9647e-03,  4.8822e-02,  2.1176e-02,  4.5215e-02,  1.6977e-02,\n",
      "         -6.4809e-03,  5.5107e-02,  2.6590e-03,  5.1952e-02,  1.6742e-02,\n",
      "         -3.5936e-02,  2.3577e-02,  4.2926e-02,  4.7127e-02,  1.5362e-02,\n",
      "         -4.5433e-02,  3.1580e-02,  4.9519e-02, -1.2192e-02,  5.7744e-02,\n",
      "         -3.4225e-02, -4.3068e-02, -2.4875e-02, -3.5421e-02, -4.2653e-02,\n",
      "         -3.9217e-02,  6.8132e-03,  5.8423e-02, -5.2300e-02, -3.3129e-02,\n",
      "          1.9688e-03,  4.5081e-02,  5.2573e-02, -1.2045e-03, -3.2094e-02,\n",
      "         -2.3950e-02,  4.9435e-02,  3.4865e-02,  2.9240e-02, -5.2974e-06,\n",
      "         -3.6245e-02,  1.1779e-02,  5.1055e-02,  4.5110e-02,  5.6593e-03,\n",
      "          2.9897e-02,  1.2192e-02,  2.4950e-02, -1.9164e-03,  1.9358e-02,\n",
      "          3.7170e-02,  5.4937e-02,  9.2483e-03, -6.0033e-02, -3.8994e-02,\n",
      "          4.1713e-02, -1.3794e-02,  4.8425e-02, -7.8520e-03,  6.1047e-02,\n",
      "         -2.2269e-03, -4.9646e-02, -5.4748e-02,  2.6858e-02,  1.5299e-02,\n",
      "          4.8018e-02,  4.4888e-02, -4.2270e-03, -3.8552e-02,  4.8792e-02,\n",
      "          4.2143e-03,  1.6095e-02,  2.4091e-02, -2.9101e-02, -3.8344e-03,\n",
      "         -8.0720e-03, -5.9255e-02, -5.8169e-02,  2.1498e-02, -5.1863e-03,\n",
      "         -2.8487e-02,  2.5307e-02,  4.1683e-02,  3.6041e-02, -4.1759e-02,\n",
      "         -3.3116e-02,  4.6073e-02,  8.6181e-03, -2.5351e-02, -2.4252e-02,\n",
      "         -2.0140e-02, -1.2889e-02,  5.0893e-02, -1.4533e-02,  5.7440e-02,\n",
      "         -1.7920e-02, -4.1878e-02,  4.7746e-02,  4.9856e-02, -2.5380e-02,\n",
      "          4.8667e-02, -1.5894e-02,  4.6558e-02, -1.6824e-02,  4.1823e-02,\n",
      "         -2.1510e-02, -4.6288e-02,  3.7205e-02,  2.3715e-02, -6.1191e-03,\n",
      "         -1.7165e-02, -8.7668e-03, -3.5437e-03, -4.1613e-02, -1.4965e-03,\n",
      "          1.1665e-02, -2.5578e-03, -2.6765e-02, -6.2383e-02, -4.5690e-02,\n",
      "          7.2294e-03,  3.4761e-02,  2.1857e-03, -1.5747e-02,  1.0872e-02,\n",
      "          6.7472e-03,  3.3099e-02,  1.0449e-03,  1.4826e-02,  5.1824e-02,\n",
      "          2.1337e-02,  2.0682e-02,  2.8203e-02,  1.8757e-02,  2.2556e-02,\n",
      "          3.5225e-02,  2.6909e-02,  3.4668e-02, -1.7102e-02,  5.2323e-02,\n",
      "         -2.9385e-02,  5.6959e-02, -2.9259e-02,  3.2775e-02,  3.8491e-02,\n",
      "          1.1532e-02],\n",
      "        [-6.1639e-02, -4.1470e-02, -2.2666e-02,  2.4949e-02,  3.8972e-02,\n",
      "          3.7418e-02,  4.4487e-02, -3.7632e-02, -5.5402e-02,  2.7430e-02,\n",
      "          1.3682e-02,  1.9421e-03, -4.3508e-02, -2.3864e-02, -1.5038e-02,\n",
      "          5.1874e-03, -4.9144e-02, -2.0143e-02,  2.5658e-02, -5.7205e-02,\n",
      "         -2.8474e-02, -7.9818e-03,  5.1084e-02,  5.1490e-02,  2.8269e-02,\n",
      "          3.9742e-02, -1.9026e-02,  5.3931e-02, -4.4850e-02,  6.0287e-02,\n",
      "          3.9859e-02,  9.8248e-03,  2.1919e-02,  2.0262e-02,  1.7206e-02,\n",
      "          1.5939e-02, -1.5498e-02, -2.6005e-02, -3.2107e-02,  3.2726e-02,\n",
      "          3.5803e-02, -6.5731e-03, -1.4375e-03, -5.2398e-02, -4.7267e-02,\n",
      "         -4.7007e-02, -6.9767e-03, -3.2461e-03, -6.0123e-02, -4.9716e-02,\n",
      "          2.8136e-02,  6.1457e-02, -2.9834e-02, -5.5291e-02, -1.8855e-02,\n",
      "         -2.1012e-02,  6.0092e-02, -4.5063e-02,  5.7796e-02,  3.6753e-03,\n",
      "         -2.0880e-03, -4.7944e-02,  3.9506e-02, -4.2288e-02, -3.5280e-02,\n",
      "         -5.1234e-02, -2.1441e-03,  1.9558e-02,  2.2375e-02,  2.3830e-02,\n",
      "          3.2692e-02, -3.0368e-02, -6.2125e-02,  5.4899e-02, -4.3671e-02,\n",
      "          5.7945e-02, -2.2830e-02, -9.9143e-03, -4.3695e-02, -1.9712e-02,\n",
      "         -5.5907e-02,  1.4015e-04,  5.0734e-02,  4.0171e-02, -4.7234e-02,\n",
      "         -4.2826e-02, -1.3698e-02,  1.1014e-02,  4.0941e-02,  2.1351e-02,\n",
      "         -2.7623e-03, -9.2971e-03, -3.4453e-02,  1.9305e-02,  6.1773e-02,\n",
      "          3.2498e-02,  9.4843e-03,  8.8315e-03,  3.6236e-02, -5.5245e-02,\n",
      "         -4.3090e-02,  3.7374e-02, -1.9549e-02,  5.0133e-02, -1.8174e-02,\n",
      "          5.1661e-03, -3.4563e-02, -4.4157e-02, -2.0681e-03,  5.0901e-02,\n",
      "          4.5049e-02,  2.4010e-02, -2.9127e-02,  4.3596e-03,  5.5026e-02,\n",
      "         -2.5480e-02,  3.1383e-02,  5.0459e-03,  2.2288e-02, -1.8548e-02,\n",
      "         -6.7494e-03,  4.4638e-02,  5.2042e-03, -6.2056e-02,  4.7894e-02,\n",
      "         -5.7434e-03, -4.6742e-02, -3.0021e-02, -5.9895e-02, -5.0976e-03,\n",
      "         -5.8798e-03, -2.6641e-02,  4.8760e-02,  1.0431e-02,  4.6420e-03,\n",
      "         -2.1010e-03, -3.7530e-02, -2.0674e-02,  3.9546e-02, -1.0599e-03,\n",
      "          4.4566e-03,  1.3437e-03, -5.3067e-02,  1.0078e-02, -3.2105e-02,\n",
      "         -6.4458e-03, -1.5906e-02, -5.6231e-02,  1.1238e-02, -4.5511e-02,\n",
      "         -4.7838e-02,  5.8757e-02,  6.1655e-02, -2.6434e-02, -2.8918e-02,\n",
      "         -5.7669e-02,  3.0019e-02, -3.3391e-02,  5.3634e-02,  2.6340e-02,\n",
      "         -2.7842e-02, -5.0302e-02,  5.7028e-02, -4.9739e-03,  6.8878e-03,\n",
      "          3.8626e-02, -2.5636e-03, -5.7026e-02,  3.5630e-02, -5.0761e-02,\n",
      "          5.6304e-02, -4.8541e-02, -2.5137e-03,  5.6487e-02,  4.7223e-02,\n",
      "          3.7693e-03,  2.5153e-02, -5.6342e-03,  2.3043e-04,  5.4715e-02,\n",
      "         -3.5628e-02,  2.5320e-02,  5.7322e-02,  4.6436e-02,  2.8911e-02,\n",
      "          3.2051e-02, -2.7197e-02, -2.4181e-02, -3.6369e-02, -2.9171e-02,\n",
      "         -6.0370e-03, -1.1727e-02,  4.4073e-02, -3.3600e-02, -1.8956e-02,\n",
      "         -2.7692e-02,  7.3507e-03,  2.1959e-02,  3.5205e-02, -3.3869e-02,\n",
      "          3.7604e-02,  2.3665e-02, -1.5126e-02,  3.5660e-02,  2.3856e-02,\n",
      "          3.6842e-02, -3.7248e-02,  1.4114e-02,  4.5503e-02, -2.8486e-02,\n",
      "         -8.6652e-03, -3.3552e-02,  4.5433e-03, -4.9697e-02,  2.7665e-02,\n",
      "          1.0909e-02, -2.1960e-02,  4.1522e-02, -3.8738e-03, -5.4214e-02,\n",
      "          5.2382e-02,  1.8169e-02, -5.6523e-02, -1.8446e-02, -6.0148e-02,\n",
      "          1.0265e-02, -7.7370e-03,  3.4625e-02, -4.4525e-02,  2.0826e-02,\n",
      "         -4.1906e-03,  1.8527e-02, -1.9105e-03, -3.4633e-02, -3.6246e-02,\n",
      "         -2.1790e-02, -9.4948e-03,  3.5246e-02, -3.2943e-02, -2.5989e-02,\n",
      "         -2.0157e-02, -1.5477e-02, -5.8888e-02,  2.7665e-02,  1.6910e-02,\n",
      "         -1.6386e-02,  2.2525e-02,  1.4049e-02,  5.3382e-02, -1.7567e-02,\n",
      "          4.7425e-02,  4.7843e-02, -6.1893e-02,  5.7514e-02, -2.3111e-02,\n",
      "          3.7878e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: module_fc.2.bias | Size: torch.Size([10]) | Values : tensor([ 0.0067, -0.0490], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
